{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import urllib\n",
    "import imghdr\n",
    "import posixpath\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.13 ('prediction_env')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n prediction_env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "\n",
    "# The nltk version is 3.0.0.\n",
    "# The scikit-learn version is 0.15.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bing:\n",
    "    def __init__(self, query, limit, output_dir, adult, timeout,  filter='', verbose=True):\n",
    "        self.download_count = 0\n",
    "        self.query = query\n",
    "        self.output_dir = output_dir\n",
    "        self.adult = adult\n",
    "        self.filter = filter\n",
    "        self.verbose = verbose\n",
    "        self.seen = set()\n",
    "\n",
    "        assert type(limit) == int, \"limit must be integer\"\n",
    "        self.limit = limit\n",
    "        assert type(timeout) == int, \"timeout must be integer\"\n",
    "        self.timeout = timeout\n",
    "\n",
    "        # self.headers = {'User-Agent': 'Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0'}\n",
    "        self.page_counter = 0\n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \n",
    "      'AppleWebKit/537.11 (KHTML, like Gecko) '\n",
    "      'Chrome/23.0.1271.64 Safari/537.11',\n",
    "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "      'Accept-Encoding': 'none',\n",
    "      'Accept-Language': 'en-US,en;q=0.8',\n",
    "      'Connection': 'keep-alive'}\n",
    "\n",
    "\n",
    "    def get_filter(self, shorthand):\n",
    "        if shorthand in [\"line\", \"linedrawing\"]:\n",
    "            return \"+filterui:photo-linedrawing\"\n",
    "        elif shorthand == \"photo\":\n",
    "            return \"+filterui:photo-photo\"\n",
    "        elif shorthand == \"clipart\":\n",
    "            return \"+filterui:photo-clipart\"\n",
    "        elif shorthand in [\"gif\", \"animatedgif\"]:\n",
    "            return \"+filterui:photo-animatedgif\"\n",
    "        elif shorthand == \"transparent\":\n",
    "            return \"+filterui:photo-transparent\"\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "    def save_image(self, link, file_path):\n",
    "        request = urllib.request.Request(link, None, self.headers)\n",
    "        image = urllib.request.urlopen(request, timeout=self.timeout).read()\n",
    "        if not imghdr.what(None, image):\n",
    "            print('[Error]Invalid image, not saving {}\\n'.format(link))\n",
    "            raise ValueError('Invalid image, not saving {}\\n'.format(link))\n",
    "        with open(str(file_path), 'wb') as f:\n",
    "            f.write(image)\n",
    "\n",
    "    \n",
    "    def download_image(self, link):\n",
    "        self.download_count += 1\n",
    "        try:\n",
    "            path = urllib.parse.urlsplit(link).path\n",
    "            filename = posixpath.basename(path).split('?')[0]\n",
    "            file_type = filename.split(\".\")[-1]\n",
    "            if file_type.lower() not in [\"jpe\", \"jpeg\", \"jfif\", \"exif\", \"tiff\", \"gif\", \"bmp\", \"png\", \"webp\", \"jpg\"]:\n",
    "                file_type = \"jpg\"\n",
    "                \n",
    "            self.save_image(link, self.output_dir.joinpath('coverart.jpg'))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            self.download_count -= 1\n",
    "            print(\"[!] Issue getting: {}\\n[!] Error:: {}\".format(link, e))\n",
    "\n",
    "    def run(self):\n",
    "        total_iter = 0\n",
    "        while (self.download_count < self.limit) and (total_iter < 10):\n",
    "            request_url = f'https://www.bing.com/images/async?q={urllib.parse.quote_plus(self.query)}&first={str(self.page_counter)}&count={str(self.limit)}&adlt={self.adult}'\n",
    "\n",
    "            request = urllib.request.Request(request_url, None, headers=self.headers)\n",
    "            response = urllib.request.urlopen(request)\n",
    "            html = response.read().decode('utf8')\n",
    "            links = re.findall('murl&quot;:&quot;(.*?)&quot;', html)\n",
    "\n",
    "            for link in links:\n",
    "                if self.download_count < self.limit:\n",
    "                    self.download_image(link)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            self.page_counter += 1\n",
    "            total_iter += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(query, limit=100, output_dir='dataset', adult_filter_off=True, \n",
    "force_replace=False, timeout=60, filter=\"\", verbose=True):\n",
    "\n",
    "    # engine = 'bing'\n",
    "    adult = 'off' if adult_filter_off else 'on'\n",
    "    image_dir = Path(output_dir).absolute()\n",
    "\n",
    "    if force_replace and Path.is_dir(image_dir):\n",
    "        shutil.rmtree(image_dir)\n",
    "\n",
    "    # check directory and create if necessary\n",
    "    try:\n",
    "        if not Path.is_dir(image_dir):\n",
    "            Path.mkdir(image_dir, parents=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('[Error]Failed to create directory.', e)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # print(\"[%] Downloading Images to {}\".format(str(image_dir.absolute())))\n",
    "    bing = Bing(query, limit, image_dir, adult, timeout, '', False)\n",
    "    bing.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.13 ('prediction_env')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n prediction_env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('prediction_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b9472ad8a7fb180cf2207525f2f6dbebf9a4fe05be313e45f977b467d9a59f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
